[{"content":"What I\u0026amp;rsquo;m building ? [!NOTE]\nLast year, I suffered a catastrophic disaster that more or less destroyed irishlab:v2.0.0. (damn you waterheater leakage !!!!) I am working on full ground up rebuild for 2025. The goal this time is to increse documentation. If you have some ideas for project, cooperation etc\u0026amp;hellip; drop me an email to irishlab.io\nMy personal goal is to have a personal cloud environment at home. Building it from scratch would help me to understand Kubernetes cluster solutions for future reference. Another advantage of building it from the bottom up is that, if something breaks, you will at least have some idea about what might be wrong.\nArchitecture Hardware Infrastructure Networking Containers Security Home Automation This is an educational project to build personal homelab to explore technologies\n","date":1729351575,"description":"Up and running","lastmod":"2024-10-26T15:26:15Z","objectID":"3976528693a0108357f4928017600865","permalink":"http://localhost:1313/","publishdate":"2024-11-23T15:26:15Z","title":"Home"},{"content":"Currently | DevSecOps - AppSec Expert AppSec Expert specializing in designing, building, and automating robust platforms in the Financial sector.\nInterested in collaborating or discussing opportunities? I\u0026amp;rsquo;d love to connect!\n","date":1729351575,"description":"Text about this post","lastmod":"2024-10-26T15:26:15Z","objectID":"a69934980f795699f7cc4d8a50a604b2","permalink":"http://localhost:1313/about/","publishdate":"2024-11-23T15:26:15Z","title":"About"},{"content":"What I\u0026amp;rsquo;m trying to achieve ? To start, let\u0026amp;rsquo;s introduce ourselves to homelabs and what they are. A homelab is an environment, computers in this context, equipped for experimentation or research. These labs can range from a single low powered device to several chunks of rack mounted devices. When I first gained an interest in homelabbing, my brain was wrapped around the idea of buying large servers and racking hardware.\nOver the year I have discovered that a homelab does not require huge server (at least not anymore). Big concept can be run on smaller hardware as long as you are curious about it.\nMy goal is to have an education environment where I can explore various DevOps techniques. Build it from scratch is also a great learning experience that helps me to understand architecture, infrastructure, networking, and so.\nAno advantage of building it from the bottom up is that, if something breaks, I can rebuild it myself with ease. Given I know myself, I tend to break, rebuild and rebreak things over an over. Therefore my homelab must have a significant level of automation to expedite each rebuild.\nFinally, I am using this homelab to host a series of services I use at home; either for home automation, media streaming and coding. Also the key uptime metric is the overall WAF (Wife Approuval Factor).\n","date":1508426775,"description":"What I'm trying to achieve ?","lastmod":"2019-10-26T15:26:15Z","objectID":"55ed2e0a9b44648ef43cbb49ae9ffb45","permalink":"http://localhost:1313/architecture/","publishdate":"2018-11-23T15:26:15Z","title":"Architecture"},{"content":"These hypervisors run on a conventional operating system (OS) just as other computer programs do. A virtual machine monitor runs as a process on the host, such as VirtualBox. Type-2 hypervisors abstract guest operating systems from the host operating system, effectively creating an isolated system that can be interacted with by the host. Examples of Type-2 hypervisor include VirtualBox and VMware Workstation.\n","date":1508426775,"description":"","lastmod":"2019-10-26T15:26:15Z","objectID":"d9641ef998374b3bce49851448d8b51d","permalink":"http://localhost:1313/architecture/baremetal/","publishdate":"2018-11-23T15:26:15Z","title":"Baremetal"},{"content":"Lorem Ipsum Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n","date":1508426775,"description":"Text about this post","lastmod":"2019-10-26T15:26:15Z","objectID":"c9609b82f5be81bc3dc5f6a2436aeee3","permalink":"http://localhost:1313/architecture/clusters/","publishdate":"2018-11-23T15:26:15Z","title":"Cluster"},{"content":"I\u0026amp;rsquo;ve always been amazed by cloud and virtualization technologies, so I decided to dive into Kubernetes and containerization. However, a few months ago, I found myself frustrated by how abstract and theoretical Kubernetes felt in online courses. I realized the best way to truly understand it was to build something real. That\u0026amp;rsquo;s how the idea of a Kubernetes homelab came to life — a hands-on project to turn my curiosity into practical skills by breaking things, fixing them, and learning along the way.\nIn this first stage, I opted to deploy the cluster on bare metal due to the limited specs of my setup, but I plan to extend my homelab by adding more nodes as VMs to explore scalability and test different technologies and configurations.\nCluster of cluster Set up a K3s cluster: A lightweight Kubernetes cluster using a Beelink Mini PC as the control plane node and worker nodes distributed across additional devices like Raspberry Pis. Persistent Storage: Leverage Longhorn for distributed storage and backups. Integrate with a NAS for additional S3-compatible storage using MinIO. Networking and Ingress: Use MetalLB for LoadBalancer functionality and Tailscale for secure ingress. Monitoring and Observability: Deploy Prometheus and Grafana for visualizing cluster health and workload performance. GitOps Automation: Adopt ArgoCD for GitOps workflows, ensuring all configurations are declarative and version-controlled. Applications: Run a suite of homelab apps like Uptime Kuma, Grafana, Prometheus or Home Assistant for practical use cases. Federation: Experiment with federated Kubernetes clusters interconnected via Tailscale. ","date":1508426775,"description":"","lastmod":"2019-10-26T15:26:15Z","objectID":"c2ee231ed7559f1da5da916d435737d9","permalink":"http://localhost:1313/architecture/clusters/k8s/","publishdate":"2018-11-23T15:26:15Z","title":"Kubernetes"},{"content":"These hypervisors run on a conventional operating system (OS) just as other computer programs do. A virtual machine monitor runs as a process on the host, such as VirtualBox. Type-2 hypervisors abstract guest operating systems from the host operating system, effectively creating an isolated system that can be interacted with by the host. Examples of Type-2 hypervisor include VirtualBox and VMware Workstation.\nCluster of cluster Creating a private cloud mean that I will need to provision various workload in various environment. Therefore I will be running Proxmox as my main virtualization environment where I can easily manage Virtual Machine (VMs) and containers (LXC), software-defined networking (SDN) , high-availability (HA) clustering, and multiple out-of-the-box tools using a single solution.\nWhile Proxmox is a great tool, I do own a large number of Single-Board Computers (SBC) in the form of Raspberry Pi of many generations. Those are resources limited and running a virtualization solution would curb what I can get out of these small computers.\n","date":1508426775,"description":"","lastmod":"2019-10-26T15:26:15Z","objectID":"99970cbe7de926e606930187680a585f","permalink":"http://localhost:1313/architecture/clusters/proxmox/","publishdate":"2018-11-23T15:26:15Z","title":"Proxmox"},{"content":"These hypervisors run on a conventional operating system (OS) just as other computer programs do. A virtual machine monitor runs as a process on the host, such as VirtualBox. Type-2 hypervisors abstract guest operating systems from the host operating system, effectively creating an isolated system that can be interacted with by the host. Examples of Type-2 hypervisor include VirtualBox and VMware Workstation.\nCluster of cluster Creating a private cloud mean that I will need to provision various workload in various environment. Therefore I will be running Proxmox as my main virtualization environment where I can easily manage Virtual Machine (VMs) and containers (LXC), software-defined networking (SDN) , high-availability (HA) clustering, and multiple out-of-the-box tools using a single solution.\nWhile Proxmox is a great tool, I do own a large number of Single-Board Computers (SBC) in the form of Raspberry Pi of many generations. Those are resources limited and running a virtualization solution would curb what I can get out of these small computers.\n","date":1508426775,"description":"","lastmod":"2019-10-26T15:26:15Z","objectID":"d0573b1eee7183ce7af632df40a7c081","permalink":"http://localhost:1313/architecture/hypervisor/","publishdate":"2018-11-23T15:26:15Z","title":"Hypervisor"},{"content":"The Plan As Eisenhower once said, In preparing for battle I have always found that plans are useless, but planning is indispensable, so I am trying to plan ahead what I will be doing in this new documented rebuild of my homelab.\nAnd as Mike Tyson also said, Everyone has a plan \u0026#39;till they get punched in the mouth, therefore I expect things not to work 100% of the time.\nWhat did I build ? My homelab design principale is essential those of a small datacenter where I host networking, compute nodes and storage nodes. The key idea is to replicate, with my own personal preference, what I could be finding in a small datacenter and using similar techniques.\nNetworking Compute Nodes Storage Nodes Servers in on-premises datacenters are generally viewed as pets, whereas servers in the cloud are considered cattle. Pets are indispensable servers where you can make configuration changes should problems arise While, Cattle are servers that can be deleted and rebuilt from scratch in case of failures.\nWith the exception of the storage nodes (actually data hosted in those storage nodes), I intent to treat all servers as cattle as much as possible given my homelab should be resiliant to failure (accidental or self-inflicted).\nDesign Principles Integrate both AMD64 and ARM64 hardware in my homelab Include various additional hardware when it makes sense (i.e.: GPU/TPU for accelerated workload, etc\u0026amp;hellip;) Run an enterprise virtualization platform based on Proxmox Proxmox Datacenter Management (PDM), to provide a unified overview of all PVE clusters and nodes in my virtualized environments Proxmox Virtual Environment (PVE), to provide virtualization platform designed for the provisioning of hyper-converged infrastructure Proxmox Backup Server (PBS), to provide seamless centralized solution for backing up virtual machines and containers running on PVE Run a Kubernetes cluster hosting most services offered at home Use hybrid AMD64/ARM64 nodes combining in the same cluster virtual machines …","date":1508426775,"description":"","lastmod":"2019-10-26T15:26:15Z","objectID":"3340333f0b7db641e389bd80fd6095c3","permalink":"http://localhost:1313/architecture/plan/","publishdate":"2018-11-23T15:26:15Z","title":"The Plan"},{"content":"Lorem Ipsum Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n","date":1508426775,"description":"Text about this post","lastmod":"2019-10-26T15:26:15Z","objectID":"92087fb1ac9e630ff0f04e20c8ac0dc2","permalink":"http://localhost:1313/architecture/servers/","publishdate":"2018-11-23T15:26:15Z","title":"Servers"},{"content":"DNS Architecture This article goes over how I am setting up my local DNS services in my homelab. Essentially this uses Pi-hole, with Unbound, sync via Nebula Sync, secure through Tailscale VPN, and redundant with Keepalived all running on Ubuntu 24.04 as Docker container. The goal is to deploy a High Availability local DNS services with syncronization between multiple including a recursive DNS resolver.\nSetup Ubuntu OS To setup Ubuntu, see this post (TBD).\nPort 53 What to do if port 53 is already in use\nWhen the Port 53 is already in Use, you can check this with this command (ubuntu):\nPort 53 is being used at your host machine, that\u0026amp;rsquo;s why you can not bind 53 to host.\nTo find what is using port 53 you can do: sudo lsof -i -P -n | grep LISTEN\nI\u0026amp;rsquo;m a 99.9% sure that systemd-resolved is what is listening to port 53.\nTo solve that you need to edit the /etc/systemd/resolved.conf and uncomment DNSStubListener and change it to no, so it looks like this: DNSStubListener=no\nAfter that reboot your system or restart the service with service systemd-resolved restart\nsudo lsof -i -P -n | grep 53 sudo nano /etc/systemd/resolved.conf # DNSStubListener=no sudo service systemd-resolved restart DNS stack Deploy the following services: Keepalived Watchdog Fail2Ban Docker Containers I usually put my container stacks into /opt/stacks on all servers, it\u0026amp;rsquo;s easier for me to find all docker worload on a given server.\nmkdir -p opt/stacks/ sudo chown -R groot:groot /opt/stacks/ Automated Installation Ansible roles ansible-playbook setup.yml -K ","date":1508426775,"description":"DNS Architecture","lastmod":"2019-10-26T15:26:15Z","objectID":"39321d592d174abb51b8e6c4c602004f","permalink":"http://localhost:1313/architecture/servers/dns/","publishdate":"2018-11-23T15:26:15Z","title":"DNS"},{"content":"General Architecture This is how I setup my typical Ubuntu server regardless of the version of configuration, just the standard things out of the box.\nManual Installation SSH Key ssh-keygen -o -a 100 -t ed25519 -f ~/.ssh/id_ed25519 -N \u0026amp;#39;\u0026amp;#39; -C ${USER}@${HOSTNAME} export GH_USER=\u0026amp;#34;irish1986\u0026amp;#34; curl https://github.com/${GH_USER}.keys \u0026amp;gt;\u0026amp;gt; ~/.ssh/authorized_keys Updates sudo apt-get update \u0026amp;amp;\u0026amp;amp; sudo apt-get upgrade -y \u0026amp;amp;\u0026amp;amp; sudo apt autoremove -y \u0026amp;amp;\u0026amp;amp; sudo apt autoclean -y Common packages sudo apt install nfs-common Users \u0026amp;amp; Groups setup passwordless sudo on Linux?\nsudo visudo ${USER) ALL=(ALL) NOPASSWD:ALL sudo visudo -c # verified it worked Security Firewall Services General stack Deploy the following services: Watchdog Fail2Ban Docker Containers I usually put my container stacks into /opt/stacks on all servers, it\u0026amp;rsquo;s easier for me to find all docker worload on a given server.\nmkdir -p opt/stacks/ sudo chown -R groot:groot /opt/stacks/ Automated Installation Ansible roles ansible-playbook setup.yml -K ","date":1508426775,"description":"General Server Architecture","lastmod":"2019-10-26T15:26:15Z","objectID":"74e98588429d0a1ddb1cb75f62a90da3","permalink":"http://localhost:1313/architecture/servers/general/","publishdate":"2018-11-23T15:26:15Z","title":"General"},{"content":"Lorem Ipsum Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n","date":1508426775,"description":"Text about this post","lastmod":"2019-10-26T15:26:15Z","objectID":"54ed7bfbaf807fe3944d91dceb2b9a00","permalink":"http://localhost:1313/container/","publishdate":"2018-11-23T15:26:15Z","title":"Containers"},{"content":"What is docker ","date":1508426775,"description":"What I'm trying to achieve ?","lastmod":"2019-10-26T15:26:15Z","objectID":"e98d1ae42acb19339e085779fb4150be","permalink":"http://localhost:1313/container/docker/","publishdate":"2018-11-23T15:26:15Z","title":"Docker"},{"content":"Homepage ","date":1508426775,"description":"","lastmod":"2019-10-26T15:26:15Z","objectID":"bb710140cccbc12346fbfa4a323ae582","permalink":"http://localhost:1313/container/docker/homepage/","publishdate":"2018-11-23T15:26:15Z","title":"Homepage"},{"content":"Nebula-Sync Create a new directory for Nebula Sync and navigate into it.\nmkdir -p /opt/stacks/nebula-sync cd /opt/stacks/nebula-sync Create our compose file.\ndocker pull ghcr.io/lovelaze/nebula-sync:v0.10.0 # pre-load the container nano compose.yml Inside of our compose.yml paste:\n--- name: nebula-sync services: nebula-sync: container_name: nebula-sync image: ghcr.io/lovelaze/nebula-sync:v0.10.0 restart: unless-stopped env_file: .env Create our .env with our variables.\nReplace with your server IPs, passwords, timezone, and how frequently you want so run this sync job.\n# This file is used to set environment variables for the Nebula-Sync Docker container. PRIMARY=\u0026amp;#34;http://192.168.1.5|abc123\u0026amp;#34; REPLICAS=\u0026amp;#34;http://192.168.1.6|abc123,http://192.168.1.7|abc123\u0026amp;#34; FULL_SYNC=false RUN_GRAVITY=true CRON=*/15 * * * * # every 15min CLIENT_SKIP_TLS_VERIFICATION=true CLIENT_RETRY_DELAY_SECONDS=5 CLIENT_TIMEOUT_SECONDS=60 TZ=\u0026amp;#34;America/Toronto\u0026amp;#34; SYNC_CONFIG_DATABASE=false SYNC_CONFIG_DEBUG=false SYNC_CONFIG_DHCP=false SYNC_CONFIG_DNS=true SYNC_CONFIG_MISC=false SYNC_CONFIG_NTP=false SYNC_CONFIG_RESOLVER=false SYNC_GRAVITY_AD_LIST_BY_GROUP=true SYNC_GRAVITY_AD_LIST=true SYNC_GRAVITY_CLIENT_BY_GROUP=false SYNC_GRAVITY_CLIENT=false SYNC_GRAVITY_DHCP_LEASES=false SYNC_GRAVITY_DOMAIN_LIST_BY_GROUP=true SYNC_GRAVITY_DOMAIN_LIST=true SYNC_GRAVITY_GROUP=true Start our compose stack as a daemon. Optionnaly, we can look at the logs and others related informations.\ndocker compose up -d docker ps | grep nebula docker logs nebula-sync ","date":1508426775,"description":"","lastmod":"2019-10-26T15:26:15Z","objectID":"e97157170b2433ddb0c29f6f25045c6d","permalink":"http://localhost:1313/container/docker/nebula-sync/","publishdate":"2018-11-23T15:26:15Z","title":"Nebula-Sync"},{"content":"PeaNUT Create a new directory for PeaNUT and navigate into it.\nmkdir -p /opt/stacks/peanut cd /opt/stacks/peanut nano compose.yml --- name: peanut services: peanut: container_name: peanut image: brandawg93/peanut:5.7.2 restart: unless-stopped volumes: - \u0026amp;#34;./config:/config\u0026amp;#34; ports: - 8080:8080 env_file: .env # This file is used to set environment variables for the PeaNUT Docker container. WEB_PORT=8080 WEB_USERNAME= \u0026amp;#34;your-username-here\u0026amp;#34; WEB_PASSWORD= \u0026amp;#34;your-password-here\u0026amp;#34; nano /opt/stacks/peanut/config/settings.yml NUT_SERVERS: - HOST: localhost PORT: 3493 USERNAME: user PASSWORD: pass INFLUX_HOST: \u0026amp;#39;\u0026amp;#39; INFLUX_TOKEN: \u0026amp;#39;\u0026amp;#39; INFLUX_ORG: \u0026amp;#39;\u0026amp;#39; INFLUX_BUCKET: \u0026amp;#39;\u0026amp;#39; INFLUX_INTERVAL: 10 ","date":1508426775,"description":"","lastmod":"2019-10-26T15:26:15Z","objectID":"af53cc95248777494c0f847fa4e20bc6","permalink":"http://localhost:1313/container/docker/peanut/","publishdate":"2018-11-23T15:26:15Z","title":"PeaNUT"},{"content":"Pihole Create a new directory for Pi-Hole and navigate into it.\nmkdir -p /opt/stacks/pihole cd /opt/stacks/pihole nano compose.yml --- name: pihole services: pihole: container_name: pihole image: ghcr.io/pi-hole/pihole:2025.04.0 restart: unless-stopped hostname: ${HOSTNAME} ports: - \u0026amp;#34;53:53/tcp\u0026amp;#34; - \u0026amp;#34;53:53/udp\u0026amp;#34; - \u0026amp;#34;80:80/tcp\u0026amp;#34; - \u0026amp;#34;443:443/tcp\u0026amp;#34; env_file: .env cap_add: - SYS_TIME - SYS_NICE volumes: - \u0026amp;#34;./pihole:/etc/pihole\u0026amp;#34; # This file is used to set environment variables for the Pi-hole Docker container. TZ=\u0026amp;#34;America/Toronto\u0026amp;#34; FTLCONF_dns_listeningMode=\u0026amp;#34;all\u0026amp;#34; FTLCONF_dns_upstreams= \u0026amp;#34;1.1.1.1;127.0.0.1#5053\u0026amp;#34; FTLCONF_webserver_api_password= \u0026amp;#34;your-password-here\u0026amp;#34; ","date":1508426775,"description":"","lastmod":"2019-10-26T15:26:15Z","objectID":"9f7a064f9930ac667434705fe6f0f8bd","permalink":"http://localhost:1313/container/docker/pihole/","publishdate":"2018-11-23T15:26:15Z","title":"Pi-Hole"},{"content":"Speed Test ","date":1508426775,"description":"","lastmod":"2019-10-26T15:26:15Z","objectID":"6be436e710de711a723004f497370f53","permalink":"http://localhost:1313/container/docker/speed-test/","publishdate":"2018-11-23T15:26:15Z","title":"Speed Test"},{"content":"Tailscale Create a new directory for Tailscale and navigate into it.\nmkdir -p /opt/stacks/tailscale cd /opt/stacks/tailscale docker pull ghcr.io/tailscale/tailscale:latest # pre-load the container nano compose.yml --- name: tailscale services: tailscale: container_name: tailscale image: ghcr.io/tailscale/tailscale:v1.82.0 restart: unless-stopped hostname: rpi5-2.local.irishla.io env_file: .env volumes: - \u0026amp;#34;./tailscale/state:/var/lib/tailscale\u0026amp;#34; devices: - /dev/net/tun:/dev/net/tun cap_add: - net_admin nano .env # This file is used to set environment variables for the Tailscale Docker container. TS_AUTHKEY=tskey-client-notAReal-OAuthClientSecret1Atawk TS_EXTRA_ARGS=--advertise-tags=tag:container TS_STATE_DIR=/var/lib/tailscale TS_USERSPACE=false ","date":1508426775,"description":"","lastmod":"2019-10-26T15:26:15Z","objectID":"d97bbe2921e71516c1ae1e0a06966d7b","permalink":"http://localhost:1313/container/docker/tailscale/","publishdate":"2018-11-23T15:26:15Z","title":"Tailscale"},{"content":"Traefik ./traefik ├── data │ ├── acme.json │ ├── config.yml │ └── traefik.yml └── cf_api_token.txt └── docker-compose.yml Create a new directory for Traefik and navigate into it.\nmkdir -p opt/stacks/traefik cd opt/stacks/traefik Create our compose file.\nnano compose.yml Inside of our compose.yml paste:\nversion: \u0026amp;#34;3.8\u0026amp;#34; services: traefik: image: traefik:v3.0 container_name: traefik restart: unless-stopped security_opt: - no-new-privileges:true networks: - proxy ports: - 80:80 - 443:443 # - 443:443/tcp # Uncomment if you want HTTP3 # - 443:443/udp # Uncomment if you want HTTP3 environment: CF_DNS_API_TOKEN_FILE: /run/secrets/cf_api_token # note using _FILE for docker secrets # CF_DNS_API_TOKEN: ${CF_DNS_API_TOKEN} # if using .env TRAEFIK_DASHBOARD_CREDENTIALS: ${TRAEFIK_DASHBOARD_CREDENTIALS} secrets: - cf_api_token env_file: .env # use .env volumes: - /etc/localtime:/etc/localtime:ro - /var/run/docker.sock:/var/run/docker.sock:ro - ./data/traefik.yml:/traefik.yml:ro - ./data/acme.json:/acme.json # - ./data/config.yml:/config.yml:ro labels: - \u0026amp;#34;traefik.enable=true\u0026amp;#34; - \u0026amp;#34;traefik.http.routers.traefik.entrypoints=http\u0026amp;#34; - \u0026amp;#34;traefik.http.routers.traefik.rule=Host(`traefik-dashboard.local.example.com`)\u0026amp;#34; - \u0026amp;#34;traefik.http.middlewares.traefik-auth.basicauth.users=${TRAEFIK_DASHBOARD_CREDENTIALS}\u0026amp;#34; - \u0026amp;#34;traefik.http.middlewares.traefik-https-redirect.redirectscheme.scheme=https\u0026amp;#34; - \u0026amp;#34;traefik.http.middlewares.sslheader.headers.customrequestheaders.X-Forwarded-Proto=https\u0026amp;#34; - \u0026amp;#34;traefik.http.routers.traefik.middlewares=traefik-https-redirect\u0026amp;#34; - \u0026amp;#34;traefik.http.routers.traefik-secure.entrypoints=https\u0026amp;#34; - \u0026amp;#34;traefik.http.routers.traefik-secure.rule=Host(`traefik-dashboard.local.example.com`)\u0026amp;#34; - \u0026amp;#34;traefik.http.routers.traefik-secure.middlewares=traefik-auth\u0026amp;#34; - \u0026amp;#34;traefik.http.routers.traefik-secure.tls=true\u0026amp;#34; - \u0026amp;#34;traefik.http.routers.traefik-secure.tls.certresolver=cloudflare\u0026amp;#34; - …","date":1508426775,"description":"","lastmod":"2019-10-26T15:26:15Z","objectID":"9b32da06aee0a3b276a325f32642e789","permalink":"http://localhost:1313/container/docker/traefik/","publishdate":"2018-11-23T15:26:15Z","title":"Nebula-Sync"},{"content":"Unbound Unbound is a private recursive DNS resolver. It can do what Google and the others do, but it is running locally on your LAN (on the Pi-hole host platform in most setups). The only client for your local unbound instance is typically Pi-hole. Run the commands below to install Unbound and access the directory to create the Pi-hole configuration file. I must convert this section to utilize a Docker container.\nsudo apt install unbound -y touch /etc/unbound/unbound.conf.d/pi-hole.conf Copy the Unbound configuration file from the Pi-hole documentation and paste it into the configuration file below. You can modify this if you\u0026amp;rsquo;d like, and there\u0026amp;rsquo;s a lot that can be done with Unbound, but we\u0026amp;rsquo;ll be using a generic setup in this tutorial.\nserver: verbosity: 0 interface: 127.0.0.1 port: 5335 do-ip4: yes do-udp: yes do-tcp: yes do-ip6: no prefer-ip6: no harden-glue: yes harden-dnssec-stripped: yes use-caps-for-id: no edns-buffer-size: 1232 prefetch: yes num-threads: 1 so-rcvbuf: 1m # Ensure privacy of local IP ranges private-address: 192.168.0.0/16 private-address: 169.254.0.0/16 private-address: 172.16.0.0/12 private-address: 10.0.0.0/8 private-address: fd00::/8 private-address: fe80::/10 After the file is saved, restart the Unbound service.\nservice unbound restart sudo reboot now Finally, you can test that Unbound is running properly by running the three commands below (found in the Unbound documentation).\ndig pi-hole.net @127.0.0.1 -p 5335 # should return an IP address dig fail01.dnssec.works @127.0.0.1 -p 5335 # should return SERVFAIL (you\u0026amp;#39;ll have to run it twice) dig dnssec.works @127.0.0.1 -p 5335 # should return NOERROR ","date":1508426775,"description":"","lastmod":"2019-10-26T15:26:15Z","objectID":"fd74a4fe48266756d2233dcf82b451e6","permalink":"http://localhost:1313/container/docker/unbound/","publishdate":"2018-11-23T15:26:15Z","title":"Unbound"},{"content":"What is kubernetes ","date":1508426775,"description":"What I'm trying to achieve ?","lastmod":"2019-10-26T15:26:15Z","objectID":"feaafff89ba8906cbe1e4006a613aca9","permalink":"http://localhost:1313/container/kubernetes/","publishdate":"2018-11-23T15:26:15Z","title":"Kubernetes"},{"content":"CICD Pipelines Continuous integration (CI) and continuous delivery (CD) are software development practices that help teams deliver code changes more often and reliably:\nContinuous integration: A practice where developers frequently merge code changes into a shared source code repository. Automated builds and tests are run to validate the changes and detect integration errors. Continuous delivery: An extension of continuous integration that automatically deploys code changes to a testing or production environment after the build stage. The final push to production can be decided by a person, an automated test, or a business rule. Continuous deployment: Automatically releases updates into the production environment. ","date":1508426775,"description":"Text about this post","lastmod":"2019-10-26T15:26:15Z","objectID":"dfc8e2f0eb0c50e7525d1b8062cd813a","permalink":"http://localhost:1313/devops/","publishdate":"2018-11-23T15:26:15Z","title":"DevOps"},{"content":"Continuous Delivery Continuous delivery is an extension of continuous integration since it automatically deploys all code changes to a testing and/or production environment after the build stage.\nThis means that on top of automated testing, you have an automated release process and you can deploy your application any time by clicking a button.\nIn theory, with continuous delivery, you can decide to release daily, weekly, fortnightly, or whatever suits your business requirements. However, if you truly want to get the benefits of continuous delivery, you should deploy to production as early as possible to make sure that you release small batches that are easy to troubleshoot in case of a problem.\nReference Continuous Deployment of Docker Compose Applications Using GitHub Actions\n","date":1508426775,"description":"","lastmod":"2019-10-26T15:26:15Z","objectID":"a9d625d4c0d47789de890ae2e9fe1d1e","permalink":"http://localhost:1313/devops/c-delivery/","publishdate":"2018-11-23T15:26:15Z","title":"Continuous Delivery"},{"content":"Continuous Deployment Continuous deployment goes one step further than continuous delivery. With this practice, every change that passes all stages of your production pipeline is released to your customers. There\u0026amp;rsquo;s no human intervention, and only a failed test will prevent a new change to be deployed to production.\nContinuous deployment is an excellent way to accelerate the feedback loop with your customers and take pressure off the team as there isn\u0026amp;rsquo;t a \u0026amp;ldquo;release day\u0026amp;rdquo; anymore. Developers can focus on building software, and they see their work go live minutes after they\u0026amp;rsquo;ve finished working on it.\n","date":1508426775,"description":"","lastmod":"2019-10-26T15:26:15Z","objectID":"caa68f134b256415fd454872c3ddeff6","permalink":"http://localhost:1313/devops/c-deployment/","publishdate":"2018-11-23T15:26:15Z","title":"Continuous Deployment"},{"content":"Developers practicing continuous integration merge their changes back to the main branch as often as possible. The developer\u0026amp;rsquo;s changes are validated by creating a build and running automated tests against the build. By doing so, you avoid integration challenges that can happen when waiting for release day to merge changes into the release branch.\nContinuous integration puts a great emphasis on testing automation to check that the application is not broken whenever new commits are integrated into the main branch.\n","date":1508426775,"description":"","lastmod":"2019-10-26T15:26:15Z","objectID":"770507b8843898075bf1c1760e387030","permalink":"http://localhost:1313/devops/ci/","publishdate":"2018-11-23T15:26:15Z","title":"Continuous Integration"},{"content":"GitHub Action GitHub Actions are a great way to automate your own software development cycle. GitHub Actions are free of charge for public repositories and provide you with a whole CI/CD platform. It allows you to automate all parts of your software supply chain and run it in virtual environments or even your own environment using self-hosted runners. But more to come on this topic.\nMuch of what used to be done with a Jenkins job can now be done with GitHub Actions. In this article, I will give you a quick start in GitHub Actions and explain what actions, workflows, events, jobs and steps are. As an example we take a JavaScript application for which we set up a test automation.\nWhat are GitHub Actions? GitHub Actions are reusable scripts that can be used on GitHub\u0026amp;rsquo;s platform for continuous integration and continuous delivery (CI/CD). You can write your own actions using JavaScript (and other languages) or use published actions from the GitHub Marketplace.\nThere are already actions for various tasks like checking for code linting, uploading code coverage reports or deploying code in the cloud (or your homelab). In this tutorial, we will use existing GitHub Actions and wire them together in a so-called \u0026amp;ldquo;workflow\u0026amp;rdquo;.\nWhat are workflows? A workflow is a description for your CI/CD pipeline on GitHub Actions. A workflow always runs one or more jobs and each job consists of steps which can be calls to GitHub Actions or regular shell commands. A workflow is triggered by an event (e.g. a commit in your branch) and runs on a virtual environment on GitHub (called \u0026amp;ldquo;hosted runner\u0026amp;rdquo;) or your own environment (called \u0026amp;ldquo;self-hosted runner\u0026amp;rdquo;).\nTest Automation with GitHub Actions To ensure that pull requests are compatible with your code, you can setup a GitHub workflow to run a test automation pipeline. I will show you how to do this by using a JavaScript demo project for which we will run npm test when new code comes in.\nSetting up a workflow …","date":1508426775,"description":"","lastmod":"2019-10-26T15:26:15Z","objectID":"e34a75ad766bdb671d764af5355e9da1","permalink":"http://localhost:1313/devops/ci/gha/","publishdate":"2018-11-23T15:26:15Z","title":"GitHub Action"},{"content":"Lorem Ipsum Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n","date":1508426775,"description":"Text about this post","lastmod":"2019-10-26T15:26:15Z","objectID":"9b92f2323195839445e3b078a072d47e","permalink":"http://localhost:1313/hardware/","publishdate":"2018-11-23T15:26:15Z","title":"Hardware"},{"content":"Lorem Ipsum Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n","date":1508426775,"description":"Text about this post","lastmod":"2019-10-26T15:26:15Z","objectID":"0d68ae8f9a435938f4997fecb38448b0","permalink":"http://localhost:1313/hardware/custom/","publishdate":"2018-11-23T15:26:15Z","title":"Custom"},{"content":"Lorem Ipsum Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n","date":1508426775,"description":"Text about this post","lastmod":"2019-10-26T15:26:15Z","objectID":"2b50badd9cdb28803b1f0ab2b03de680","permalink":"http://localhost:1313/hardware/custom/nas/","publishdate":"2018-11-23T15:26:15Z","title":"NAS"},{"content":"Lorem Ipsum Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n","date":1508426775,"description":"Text about this post","lastmod":"2019-10-26T15:26:15Z","objectID":"b6064cf3ecfbaba2ca6bec80bdb8832f","permalink":"http://localhost:1313/hardware/dell/","publishdate":"2018-11-23T15:26:15Z","title":"Dell"},{"content":"aaaaaa\nvvvv\naaa\n","date":1508248845,"description":"","lastmod":"2017-10-17T14:00:45Z","objectID":"62f13c9f0ab99e3f88e1b4cdc12e29de","permalink":"http://localhost:1313/hardware/dell/micro_x060/","publishdate":"2017-10-17T14:00:45Z","title":"Dell Micro x060"},{"content":"Lorem Ipsum My favourite Raspberry Pi production tool\n","date":1508426775,"description":"Text about this post","lastmod":"2019-10-26T15:26:15Z","objectID":"5c27b95f6dad06bc80a1478b7acdbaaf","permalink":"http://localhost:1313/hardware/iot/rack_mon/","publishdate":"2018-11-23T15:26:15Z","title":"Raspberry Pi"},{"content":"Lorem Ipsum Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\nHardware RPi 1A RPi 2B RPi 3 RPi 4 RPi 5 RPi Twearking sudo rpi-eeprom-config \u0026amp;ndash;edit PSU_MAX_CURRENT=5000\n/boot/firmware/config.txt\n[all] arm_freq=3000 dtparamw=watchdog=on gpu_freq=1000 gpu_mem=16 max_usb_current=1 over_voltage_delta=50000 usb_max_current_enable=1\n","date":1508426775,"description":"Text about this post","lastmod":"2019-10-26T15:26:15Z","objectID":"ea3a01928321dff668e69c3c9c625a1c","permalink":"http://localhost:1313/hardware/rpi/","publishdate":"2018-11-23T15:26:15Z","title":"Raspberry Pi"},{"content":"Lorem Ipsum Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n","date":1508426775,"description":"Text about this post","lastmod":"2019-10-26T15:26:15Z","objectID":"b0942fad5f606feb198e5a9ff548a707","permalink":"http://localhost:1313/network/","publishdate":"2018-11-23T15:26:15Z","title":"Network"},{"content":"aaaaaa\nvvvv\naaa\n","date":1508248845,"description":"","lastmod":"2017-10-17T14:00:45Z","objectID":"9c2c03075454be67f9bf40298b4dae89","permalink":"http://localhost:1313/network/isp/","publishdate":"2017-10-17T14:00:45Z","title":"Internet Service Provider"},{"content":"Lorem Ipsum Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n","date":1508426775,"description":"Text about this post","lastmod":"2019-10-26T15:26:15Z","objectID":"01c4be0bd9e496147d26dbcaa62df466","permalink":"http://localhost:1313/network/tp-link/","publishdate":"2018-11-23T15:26:15Z","title":"TP-Link"},{"content":"aaaaaa\nvvvv\naaa\n","date":1508248845,"description":"","lastmod":"2017-10-17T14:00:45Z","objectID":"18072308aee4d4e7835ae232d3c5ca1f","permalink":"http://localhost:1313/network/tp-link/omada/","publishdate":"2017-10-17T14:00:45Z","title":"Omada"},{"content":"Lorem Ipsum Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n","date":1508426775,"description":"Text about this post","lastmod":"2019-10-26T15:26:15Z","objectID":"038662c8ff65dcecc66b741874daf505","permalink":"http://localhost:1313/os/","publishdate":"2018-11-23T15:26:15Z","title":"Operating System"},{"content":"Lorem Ipsum Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n","date":1508426775,"description":"Text about this post","lastmod":"2019-10-26T15:26:15Z","objectID":"51358ba78ed586cf002a58267a358218","permalink":"http://localhost:1313/os/linux/","publishdate":"2018-11-23T15:26:15Z","title":"Linux"},{"content":"Lorem Ipsum Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n","date":1508426775,"description":"Text about this post","lastmod":"2019-10-26T15:26:15Z","objectID":"6f59881a8a46e239f0c414d30208970e","permalink":"http://localhost:1313/os/linux/pikvm/","publishdate":"2018-11-23T15:26:15Z","title":"PiKVM"},{"content":"Lorem Ipsum Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n","date":1508426775,"description":"Text about this post","lastmod":"2019-10-26T15:26:15Z","objectID":"764ac1ee204513d39e2b62d373548596","permalink":"http://localhost:1313/os/linux/proxmox/","publishdate":"2018-11-23T15:26:15Z","title":"Proxmox"},{"content":"Lorem Ipsum Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\nReference Setup Synology NFS for Proxmox Backup Server Datastore ","date":1508426775,"description":"Text about this post","lastmod":"2019-10-26T15:26:15Z","objectID":"5c48945dc00345bd2bd32b31098eeda3","permalink":"http://localhost:1313/os/linux/proxmox/pbs/","publishdate":"2018-11-23T15:26:15Z","title":"Proxmox Backup Server"},{"content":"Lorem Ipsum Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n","date":1508426775,"description":"Text about this post","lastmod":"2019-10-26T15:26:15Z","objectID":"118195186e3aec3e0e7990f678652b89","permalink":"http://localhost:1313/os/linux/proxmox/pdm/","publishdate":"2018-11-23T15:26:15Z","title":"Proxmox Datacenter Management"},{"content":"Lorem Ipsum Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\nReference Install TrueNAS Scale in Proxmox VE ","date":1508426775,"description":"Text about this post","lastmod":"2019-10-26T15:26:15Z","objectID":"385d004fd320fcaefb45a5eb5f969875","permalink":"http://localhost:1313/os/linux/proxmox/pve/","publishdate":"2018-11-23T15:26:15Z","title":"Proxmox Virtual Environment"},{"content":"Lorem Ipsum Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\nReference Install TrueNAS Scale in Proxmox VE ","date":1508426775,"description":"Text about this post","lastmod":"2019-10-26T15:26:15Z","objectID":"e59893be5ed8b18481b281859d262698","permalink":"http://localhost:1313/os/linux/truenas/","publishdate":"2018-11-23T15:26:15Z","title":"TrueNAS Scale"},{"content":"Ubuntu Ubuntu is a free and open-source Linux-based operating system developed by Canonical and a community of developers. It\u0026amp;rsquo;s a popular choice for desktop, server, and IoT devices. Ubuntu is known for its user-friendly interface, wide range of software, and strong community support.\nEdition Desktop Server IoT Cloud Image Release Ubuntu 25.04 (Plucky Puffin) Ubuntu 24.10 (Oracular Oriole) Ubuntu 24.04.2 LTS (Noble Numbat) Ubuntu 22.04.5 LTS (Jammy Jellyfish) Ubuntu 20.04.6 LTS (Focal Fossa) Cloud-Init ","date":1508426775,"description":"How I setup my Ubuntu ","lastmod":"2019-10-26T15:26:15Z","objectID":"f6aa3a8140632763af3024fd40b7ee1f","permalink":"http://localhost:1313/os/linux/ubuntu/","publishdate":"2018-11-23T15:26:15Z","title":"Ubuntu"},{"content":"Lorem Ipsum Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n","date":1508426775,"description":"Text about this post","lastmod":"2019-10-26T15:26:15Z","objectID":"d049c15a408d068228d7485c61118885","permalink":"http://localhost:1313/os/macos/","publishdate":"2018-11-23T15:26:15Z","title":"Windows"},{"content":"Lorem Ipsum Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n","date":1508426775,"description":"Text about this post","lastmod":"2019-10-26T15:26:15Z","objectID":"41a24541a89117ebea35a3365a6ed783","permalink":"http://localhost:1313/os/synology/","publishdate":"2018-11-23T15:26:15Z","title":"Synology"},{"content":"Lorem Ipsum Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n","date":1508426775,"description":"Text about this post","lastmod":"2019-10-26T15:26:15Z","objectID":"b81590b5b172a55cabf8abcefb64337c","permalink":"http://localhost:1313/os/windows/","publishdate":"2018-11-23T15:26:15Z","title":"Windows"},{"content":"aaaaaa\nvvvv\naaa\n","date":1508248845,"description":"","lastmod":"2017-10-17T14:00:45Z","objectID":"1a1562bdc28add2476011de662830edc","permalink":"http://localhost:1313/os/windows/wsl2/","publishdate":"2017-10-17T14:00:45Z","title":"WSL2"},{"content":"Lorem Ipsum Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n","date":1508426775,"description":"Text about this post","lastmod":"2019-10-26T15:26:15Z","objectID":"57278392b25fa28b4b6a326da5a5ac14","permalink":"http://localhost:1313/services/","publishdate":"2018-11-23T15:26:15Z","title":"Services"},{"content":"Docker is an open-source platform that allows developers to package applications into containers, which are standardized, executable packages containing everything the application needs to run, including code, runtime environment, libraries, and system tools. This enables developers to build, deploy, and manage applications in a consistent and portable manner. Here\u0026amp;rsquo;s a more detailed breakdown:\nContainers: Docker uses containers, which are lightweight, standalone, and self-contained environments that isolate applications and their dependencies. Docker Engine: The core of Docker is the Docker Engine, a client-server application that manages the containers. Docker Images: Docker images are read-only templates from which containers are created. They are built using Dockerfiles, which are instructions for creating the image. Docker Hub: Docker Hub is a public registry where users can share and discover container images. Benefits of using Docker: Docker simplifies application development and deployment, improves consistency across environments, and facilitates collaboration among developers, according to Docker docs and Docker. Manual Installation cd /tmp curl -fsSL https://get.docker.com -o /get-docker.sh sudo sh ./get-docker.sh --dry-run sudo sh ./get-docker.sh Once Docker has finished installing to your Raspberry Pi, there are a couple more things we need to do. For another user to be able to interact with Docker, it needs to be added to the docker group.\nSo, our next step is to add our current user to the docker group by using the usermod command as shown below. By using \u0026amp;ldquo;$USER\u0026amp;rdquo; we are inserting the environment variable that stores the current users name.\nSince we made some changes to our user, we will now need to log out and log back in for it to take effect. You can log out by running the following command in the terminal.\nsudo usermod -aG docker $USER # an logout docker run hello-world Automated Installation Ansible roles ansible-playbook …","date":1508426775,"description":"","lastmod":"2019-10-26T15:26:15Z","objectID":"73fc346480c93d74141e013004b543da","permalink":"http://localhost:1313/services/docker/","publishdate":"2018-11-23T15:26:15Z","title":"Setup Docker"},{"content":"Fail2Ban Manual Installation Automated Installation Ansible roles ansible-playbook fail2ban.yml -K Testing it ","date":1508426775,"description":"","lastmod":"2019-10-26T15:26:15Z","objectID":"dcbc247f1792bd985bc80e63a2f8f7f7","permalink":"http://localhost:1313/services/fail2ban/","publishdate":"2018-11-23T15:26:15Z","title":"Fail2Ban"},{"content":"Lorem Ipsum Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n","date":1508426775,"description":"Text about this post","lastmod":"2019-10-26T15:26:15Z","objectID":"2858329dff7260da2e47ceccf173ebdf","permalink":"http://localhost:1313/services/k3s/","publishdate":"2018-11-23T15:26:15Z","title":"K3S"},{"content":"Master / Control In our case: control01\nThis is our primary node.\nWe are going to install the K3s version of Kubernetes, that is lightweight enough for out single board computers to handle. Use the following command to download and initialize K3s\u0026amp;rsquo; master node.\ncurl -sfL https://get.k3s.io | sh -s - --write-kubeconfig-mode 644 --disable servicelb --token some_random_password --node-taint CriticalAddonsOnly=true:NoExecute --bind-address 192.168.0.10 --disable-cloud-controller --disable local-storage Some explanations:\n\u0026amp;ndash;write-kubeconfig-mode 644 - This is the mode that we want to use for the kubeconfig file. Its optional, but needed if you want to connect to Rancher manager later on. \u0026amp;ndash;token - This is the token that we want to use to connect to the K3s master node. Choose a random password, but keep remember it. \u0026amp;ndash;disable-cloud-controller - This is the flag that we want to use to disable the K3s cloud controller. I don\u0026amp;rsquo;t think I need it. \u0026amp;ndash;disable local-storage - This is the flag that we want to use to disable the K3s local storage. I\u0026amp;rsquo;m going to setup longhorn storage provider instead. \u0026amp;ndash;disable servicelb - This is the flag that we want to use to disable the service load balancer. (We will use metallb instead) \u0026amp;ndash;node-taint - This is the flag that we want to use to add a taint to the K3s master node. I\u0026amp;rsquo;ll explain taints later on, but it will mark the node to not run any containers except the ones that are critical. \u0026amp;ndash;bind-address - This is the flag that we want to use to bind the K3s master node to a specific IP address. ","date":1508426775,"description":"Text about this post","lastmod":"2019-10-26T15:26:15Z","objectID":"5fea65ae0485e441934a08b3070ae826","permalink":"http://localhost:1313/services/k3s/k3s/","publishdate":"2018-11-23T15:26:15Z","title":"K3S Install"},{"content":"Lorem Ipsum Most of the setup of the OS was already done for us by the bootstrap file, before we had to set up manually on Ubuntu following:\nHostname Update OS Removing snap Disable swap Remove ipv6 RPi Most of the setup of the OS was already done for us by the bootstrap file, before we had to set up manually on Ubuntu following:\nEdit to cmdline.txt Disable green led Pretty much everything is done for us by the bootstrap file. So much time saved ! And super easy and quick way to bring up new node.\n","date":1508426775,"description":"Text about this post","lastmod":"2019-10-26T15:26:15Z","objectID":"9b51bf02f41b82318391aa03632ef2d9","permalink":"http://localhost:1313/services/k3s/prepare/","publishdate":"2018-11-23T15:26:15Z","title":"Preparation"},{"content":"Keepalived Keepalived is designed to run on two separate hosts but share a virtual IP address. This ensures that if one goes down (the master), the backup will take over using the same virtual IP. In this example, the virtual IP is used as our backup DNS server.\nDNS consideration I like to pre-reserve a DNS entry for my virtual IP address (which I will call vip from now on).\nManual Installation Install Keepalived on both instances of Pi-hole where you\u0026amp;rsquo;d like High Availability. Get the interface name (mine is eth0), then modify the config file.\nsudo apt install keepalived libipset13 ip a Paste this information into the configuration file of the master and modify it as needed.\nsudo nano /etc/keepalived/keepalived.conf global_defs { router_id dns-01 max_auto_priority enable_script_security script_user groot } vrrp_instance VI_1 { state MASTER interface eth0 virtual_router_id 253 priority 100 advert_int 1 unicast_src_ip 192.168.1.5 unicast_peer { 192.168.1.7 } authentication { auth_type PASS auth_pass AdfG4IJK } virtual_ipaddress { 192.168.1.253/24 } } Paste this information into the configuration file of the backup and modify it as needed.\nsudo nano /etc/keepalived/keepalived.conf global_defs { router_id dns-01 max_auto_priority enable_script_security script_user groot } vrrp_instance VI_1 { state BACKUP interface eth0 virtual_router_id 253 priority 10 advert_int 1 unicast_src_ip 192.168.1.7 unicast_peer { 192.168.1.5 } authentication { auth_type PASS auth_pass AdfG4IJK } virtual_ipaddress { 192.168.1.253/24 } } Enable the Keepalived service on both instances, reboot, and then check the status to ensure it\u0026amp;rsquo;s running.\nsudo systemctl enable --now keepalived.service sudo reboot now sudo systemctl status keepalived.service Next, we tell the keepalived service to wait on network-online.target. Bring up an editor for overriding the keepalived.service unit:\nsudo cp /usr/lib/systemd/system/keepalived.service /etc/systemd/system/keepalived.service Save the file in …","date":1508426775,"description":"","lastmod":"2019-10-26T15:26:15Z","objectID":"10b5b9237466a7ab01f4c44afde2457b","permalink":"http://localhost:1313/services/keepalived/","publishdate":"2018-11-23T15:26:15Z","title":"Keepalived"},{"content":"Nut UPS Network UPS Tools project is to provide support for Power Devices, such as Uninterruptible Power Supplies, Power Distribution Units, Automatic Transfer Switches, Power Supply Units and Solar Controllers. NUT provides a common protocol and set of tools to monitor and manage such devices, and to consistently name equivalent features and data points, across a vast range of vendor-specific protocols and connection media types.\nHardware consideration Connect your UPS via USB before starting this.\nManual Installation lsusb sudo apt update sudo apt install nut nut-client nut-server sudo nut-scanner -U sudo nano /etc/nut/ups.conf sudo nano /etc/nut/upsmon.conf sudo nano /etc/nut/upsd.conf sudo nano /etc/nut/nut.conf sudo nano /etc/nut/upsd.users sudo nano /etc/udev/rules.d/99-nut-ups.rules Automated Installation Ansible roles ansible-playbook nut.yml -K Testing it ","date":1508426775,"description":"","lastmod":"2019-10-26T15:26:15Z","objectID":"a2031e600ec270d1b0650d0148b9b817","permalink":"http://localhost:1313/services/nut/","publishdate":"2018-11-23T15:26:15Z","title":"Nut"},{"content":"Tailscale Tailscale makes creating software-defined networks easy: securely connecting users, services, and devices. I am using my DNS servers as VPN exit-nodes which exposes my services outside of my local network while adding a layer of security during my travel.\nThese steps are for Ubuntu 24.04 (noble) and once I convert this to Ansible it should be automated.\ncurl -fsSL https://pkgs.tailscale.com/stable/ubuntu/noble.noarmor.gpg | sudo tee /usr/share/keyrings/tailscale-archive-keyring.gpg \u0026amp;gt;/dev/null curl -fsSL https://pkgs.tailscale.com/stable/ubuntu/noble.tailscale-keyring.list | sudo tee /etc/apt/sources.list.d/tailscale.list sudo apt-get update sudo apt-get install tailscale -y Connect your machine to your Tailscale network and authenticate in your browser:\nsudo tailscale up --accept-dns=false --advertise-exit-node --advertise-routes=10.0.10.0/24 sudo tailscale set --auto-update Tailscale documentation is good to follow from here.\n","date":1508426775,"description":"","lastmod":"2019-10-26T15:26:15Z","objectID":"4c56c5393eb6d67fcc31aa207714f23c","permalink":"http://localhost:1313/services/tailscale/","publishdate":"2018-11-23T15:26:15Z","title":"Tailscale"},{"content":"Watchdog In Linux, a watchdog is a mechanism, either hardware or software, that monitors the system\u0026amp;rsquo;s health and automatically reboots it if it becomes unresponsive or crashes. It works by periodically sending a \u0026amp;ldquo;heartbeat\u0026amp;rdquo; signal to a timer. If the system fails to send the heartbeat within a specific timeframe, the watchdog triggers a reboot. Here\u0026amp;rsquo;s a more detailed breakdown: Purpose: The primary goal of a watchdog is to ensure the system remains operational, even in the face of software bugs or hardware failures. Mechanism: The watchdog, often implemented as a hardware timer or software daemon, continuously monitors the system. It sends a \u0026amp;ldquo;kick\u0026amp;rdquo; or \u0026amp;ldquo;heartbeat\u0026amp;rdquo; signal to a timer at regular intervals. Reboot Trigger: If the system fails to send the heartbeat within the timeout period, the watchdog assumes the system is unresponsive and triggers a reboot. This can be a hardware reset or a software-initiated reboot, depending on the implementation. Types: Hardware Watchdogs: These are dedicated hardware chips that monitor the system and can directly trigger a reset. Software Watchdogs: These are software programs that monitor the system and can trigger a software-initiated reboot. Linux Implementation: In Linux, the watchdog is often represented by a special device file, /dev/watchdog. Software daemons like watchdog write to this file to \u0026amp;ldquo;kick\u0026amp;rdquo; the watchdog, preventing it from triggering a reboot. Benefits: Watchdogs are particularly useful in embedded systems and servers that need to operate without human intervention for extended periods. They help ensure high reliability and availability.\nHardware consideration RPi ls -la /dev/watchdog* echo \u0026amp;#34;dtparam=watchdog=on\u0026amp;#34; \u0026amp;gt;\u0026amp;gt; \u0026amp;#34;/boot/firmware/config.txt\u0026amp;#34; Proxmox Host Proxmox Guest Manual Installation ls -la /dev/watchdog* sudo apt update sudo apt upgrade sudo apt install watchdog -y sudo nano /etc/watchdog.conf Edit watchdog timer with command: …","date":1508426775,"description":"","lastmod":"2019-10-26T15:26:15Z","objectID":"a85091dc6c8e70b5104b829b4d1d3f46","permalink":"http://localhost:1313/services/watchdog/","publishdate":"2018-11-23T15:26:15Z","title":"Watchdog"}]
